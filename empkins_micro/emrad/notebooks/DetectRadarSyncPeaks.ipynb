{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#FF7F50\">Notebook used to detect if there is a **Sync_In** signal present in the radar data</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from empkins_io.datasets.d03.micro_gapvii._dataset import MicroBaseDataset\n",
    "from pathlib import Path\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#FF7F50\">First we rename all raw emrad .h5 files correctly</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fnmatch\n",
    "import glob\n",
    "import re\n",
    "for raw_emrad_dir in glob.glob(\"C:/Users/clark/Documents/Studium/Bachelorarbeit/data/data_per_subject/VP_[0-9][0-9]/*/emrad/raw\"):\n",
    "    res_vp = re.findall(\"VP_(\\d+)\", raw_emrad_dir)\n",
    "    res_con = [s.replace('\\\\', '') for s in re.findall(\".tsst\", raw_emrad_dir)]\n",
    "    files = [file for file in os.listdir(raw_emrad_dir) if fnmatch.fnmatch(file, '*.h5')]\n",
    "    new_file_name = 'emrad_data_vp_' + res_vp[0] + '_' + res_con[0] + '.h5'\n",
    "    if (len(files) == 1):\n",
    "        os.rename(os.path.join(raw_emrad_dir,files[0]), os.path.join(raw_emrad_dir, new_file_name))\n",
    "    elif (len(files) > 1):\n",
    "        os.rename(os.path.join(raw_emrad_dir, [s for s in files if \"emrad\" in s][0]), os.path.join(raw_emrad_dir, new_file_name))\n",
    "    \n",
    "#count = 0\n",
    "#for root, dirs, files in os.walk(r\"C:\\Users\\clark\\Documents\\Studium\\Bachelorarbeit\\data\"):\n",
    "#    for file in files:\n",
    "#        if fnmatch.fnmatch(file, 'emrad_data_vp_*_*tsst.h5'):\n",
    "#            count +=1\n",
    "#            print(os.path.join(root, file))\n",
    "#print(count)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#FF7F50\">Now we do the check for the Sync_In peak in the emrad signal, printing the result</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detected_radar_sync_peaks(): \n",
    "\n",
    "    ## Create CSV file for storing the results of the search\n",
    "    #csv_header_string = [\"Participant\", \"Condition\", \"Node\", \"Sync_In Peak found (y/n)\"]\n",
    "\n",
    "    data = MicroBaseDataset(Path(r\"C:\\Users\\clark\\Documents\\Studium\\Bachelorarbeit\\data\"))\n",
    "    # group all data by participant and condition\n",
    "    grouped_data = data.groupby(['subject', 'condition'])\n",
    "\n",
    "    # loop over groups\n",
    "    for row in grouped_data:\n",
    "        \n",
    "        if (row.group[0] in data.MISSING_DATA):\n",
    "            continue\n",
    "\n",
    "        radar_data, _ = row.emrad\n",
    "\n",
    "        for node, new_df in radar_data.groupby(axis = 1, level=0):\n",
    "\n",
    "            if len(np.argwhere(new_df[node]['Sync_In'].values == 1))==0:\n",
    "\n",
    "                print(\"No Sync_In peak found for \" + row.group[0] + \", \" + row.group[1] + \"!\")\n",
    "                break\n",
    "\n",
    "    ###################\n",
    "    #THE OUT-COMMENTED CODE FOLLOWING CAN BE USED TO WRITE THE RESULTS OF THIS CHECK INTO A CSV FILE\n",
    "    ###################\n",
    "\n",
    "    #with open(\"detected_sync_peaks.csv\", 'w', newline='') as file:\n",
    "\n",
    "    #    writer = csv.writer(file)\n",
    "    #    writer.writerow(csv_header_string)\n",
    "\n",
    "    #   data = MicroBaseDataset(Path(r\"C:\\Users\\clark\\Documents\\Studium\\Bachelorarbeit\\data\"))\n",
    "    #    # group all data by participant and condition\n",
    "    #    grouped_data = data.groupby(['subject', 'condition'])\n",
    "\n",
    "    #    # loop over groups\n",
    "    #    for row in grouped_data:\n",
    "    #        if (row.group[0] in data.MISSING_DATA):\n",
    "    #            continue\n",
    "    #       # next entry specifying the participant and the condition\n",
    "    #        new_entry = [row.group[0], row.group[1]]\n",
    "    #        radar_data, _ = row.emrad\n",
    "    #        for node, new_df in radar_data.groupby(axis = 1, level=0):\n",
    "    #            # append the radar node to the new index\n",
    "    #            new_node = new_entry.copy()\n",
    "    #            new_node.append(node)\n",
    "    #            # search for the sync peak and document the result\n",
    "    #            new_node.append(\"y\" if len(np.argwhere(new_df[node]['Sync_In'].values == 1))>0 else \"n\")\n",
    "\n",
    "    #            # write the complete result to the csv file\n",
    "    #            writer.writerow(new_node)\n",
    "\n",
    "    #    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Sync_In peak found for VP_02, tsst!\n",
      "No Sync_In peak found for VP_02, ftsst!\n",
      "No Sync_In peak found for VP_03, tsst!\n",
      "No Sync_In peak found for VP_03, ftsst!\n"
     ]
    }
   ],
   "source": [
    "detected_radar_sync_peaks()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envBachelorThesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
